{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('./QUTZS_final.xlsx')\n",
    "# print(df.head())\n",
    "# print(df.info())\n",
    "# print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975c5c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Label', 'pkt arrival time_sv1', 'MACsrc_sv1', 'MACdst_sv1',\n",
       "       'APPID_sv1', 'SVlength_sv1', 'noASDU_sv1', 'svID1_sv1', 'smpCnt1_sv1',\n",
       "       'Data1_sv1',\n",
       "       ...\n",
       "       'datset_GOOSE3', 'goID_GOOSE3', 't_GOOSE3', 'stNum_GOOSE3',\n",
       "       'sqNum_GOOSE3', 'simulation_GOOSE3', 'confRev_GOOSE3', 'ndsCom_GOOSE3',\n",
       "       'num of data_GOOSE3', 'data_GOOSE3'],\n",
       "      dtype='object', length=139)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c79e6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/csu/Liyi/git_space/QUT-ZSS-2023-SV/Datasets/Processed dataset (supervised ML)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adc921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "root_dir = Path(\"./Benign-behaviour-only\")\n",
    "\n",
    "print(\"Searching in:\", root_dir)\n",
    "\n",
    "# 忽略大小写搜索 xlsx\n",
    "xlsx_files = list(root_dir.rglob(\"*QUTZS_final.xlsx\"))\n",
    "\n",
    "print(f\"Found {len(xlsx_files)} files.\")\n",
    "\n",
    "for xlsx_path in xlsx_files:\n",
    "    try:\n",
    "        print(\"\\nProcessing:\", xlsx_path)\n",
    "        df = pd.read_excel(xlsx_path)\n",
    "        final_df = generate_final_df(df)\n",
    "\n",
    "        # 输出文件名，如 QUTZS_final_ics_logs.csv\n",
    "        out_path = xlsx_path.with_name(xlsx_path.stem + \"_ics_logs.csv\")\n",
    "\n",
    "        final_df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "        print(\"Saved:\", out_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed {xlsx_path}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d3ab3",
   "metadata": {},
   "source": [
    "### 加上历史数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c9f9885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching in: Benign-behaviour-only\n",
      "Found 11 files.\n",
      "\n",
      "Processing: Benign-behaviour-only/105/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/108/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/104/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/0/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/109/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/102/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/107/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/101/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/103/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/106/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n",
      "\n",
      "Processing: Benign-behaviour-only/110/QUTZS_final.xlsx\n",
      "Error: 'PosixPath' object has no attribute 'endswith'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def extract_groups(columns):\n",
    "    groups = set()\n",
    "    for col in columns:\n",
    "        m = re.search(r\"(sv\\d+|SV\\d+|goose\\d+|GOOSE\\d+)\", col)\n",
    "        if m:\n",
    "            groups.add(m.group().lower())\n",
    "    return list(groups)\n",
    "\n",
    "def format_single_group(row: pd.Series, g: str, columns: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    格式化单个 GOOSE 或 SV 数据组，确保时间戳和关键字段被包含。\n",
    "    \"\"\"\n",
    "    # --- 1. 查找时间戳字段 ---\n",
    "    if \"goose\" in g.lower():\n",
    "        timestamp_col = next((c for c in columns if c.lower().startswith('t_goose') and g in c.lower()), None)\n",
    "    elif \"sv\" in g.lower():\n",
    "        timestamp_col = next((c for c in columns if 'pkt arrival time' in c.lower() and g in c.lower()), None)\n",
    "    else:\n",
    "        timestamp_col = None\n",
    "        \n",
    "    macsrc_col    = next((c for c in columns if (\"src\" in c.lower()) and g in c.lower()), None)\n",
    "    macdst_col    = next((c for c in columns if (\"dst\" in c.lower()) and g in c.lower()), None)\n",
    "    appid_col     = next((c for c in columns if \"appid\" in c.lower() and g in c.lower()), None)\n",
    "    stnum_col     = next((c for c in columns if \"stnum\" in c.lower() and g in c.lower()), None)\n",
    "    sqnum_col     = next((c for c in columns if \"sqnum\" in c.lower() and g in c.lower()), None)\n",
    "\n",
    "\n",
    "    # --- 2. 字段值提取 ---\n",
    "    timestamp = row.get(timestamp_col, \"N/A\")\n",
    "    macsrc    = row.get(macsrc_col, \"N/A\")\n",
    "    appid     = row.get(appid_col, \"N/A\")\n",
    "    stnum     = row.get(stnum_col, None)\n",
    "    sqnum     = row.get(sqnum_col, None)\n",
    "    \n",
    "    \n",
    "    msg_type = \"SV\" if \"sv\" in g.lower() else \"GOOSE\"\n",
    "    \n",
    "    base = f\"{msg_type}_PKT (ts={timestamp}, src={macsrc}, APPID={appid}\"\n",
    "\n",
    "    # GOOSE 特有字段\n",
    "    if msg_type == \"GOOSE\":\n",
    "        if pd.notna(stnum):\n",
    "            base += f\", stNum={int(stnum)}\"\n",
    "        if pd.notna(sqnum):\n",
    "            base += f\", sqNum={int(sqnum)}\"\n",
    "    \n",
    "    additional = []\n",
    "    ignore_cols = {timestamp_col, macsrc_col, macdst_col, appid_col, stnum_col, sqnum_col}\n",
    "    \n",
    "    # --- 3. 提取额外数据字段 ---\n",
    "    for col in columns:\n",
    "        # 确保列名包含当前分组标记（例如 'sv1'），且不是基础忽略字段\n",
    "        if g.lower() in col.lower() and col not in ignore_cols:\n",
    "            val = row[col]\n",
    "            if pd.notna(val):\n",
    "                \n",
    "                final_key_name = col.strip() \n",
    "\n",
    "                # 针对布尔/数值进行格式化 (保持不变)\n",
    "                if isinstance(val, (bool, np.bool_)):\n",
    "                    val_str = \"True\" if val else \"False\"\n",
    "                elif isinstance(val, (float, np.floating)):\n",
    "                    val_str = f\"{val:.4f}\"\n",
    "                else:\n",
    "                    val_str = str(val)\n",
    "                    \n",
    "                # 确保不包含时间戳或 MAC 等已在 base 中出现的字段。\n",
    "                if not any(keyword in final_key_name.lower() for keyword in [\"time\", \"ts\", \"src\", \"dst\", \"appid\", \"stnum\", \"sqnum\", \"pkt arrival\"]):\n",
    "                    additional.append(f\"{final_key_name}={val_str}\")\n",
    "\n",
    "    if additional:\n",
    "        base += \", \" + \", \".join(additional)\n",
    "    \n",
    "    base += \")\"\n",
    "    return base\n",
    "\n",
    "def row_to_single_log(row: pd.Series, columns: List[str], groups: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    生成一个时间步（一行数据）的所有事件序列，以分号分隔。\n",
    "    移除顶层时间戳包装，时间戳已嵌入到每个 packet 中。\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for g in groups:\n",
    "        event = format_single_group(row, g, columns)\n",
    "        parts.append(event)\n",
    "\n",
    "    return \"; \".join(parts)\n",
    "\n",
    "def analyze_numeric_diffs(diff_list: List[float], is_time_or_counter: bool = False):\n",
    "    \"\"\"\n",
    "    分析差分列表，返回语义标签。\n",
    "    is_time_or_counter: 如果为 True，则应用针对时间/计数器的宽松规则。\n",
    "    \"\"\"\n",
    "    semantics = []\n",
    "    \n",
    "    # 阈值逻辑 (保持不变)\n",
    "    JUMP_THRESHOLD = 100 \n",
    "\n",
    "    if not diff_list:\n",
    "        return \"steady\"\n",
    "    \n",
    "    # 判断是否存在显著非零变化\n",
    "    has_non_zero_diff = any(abs(d) > 1e-6 for d in diff_list)\n",
    "\n",
    "    if not has_non_zero_diff:\n",
    "        return \"steady\"\n",
    "\n",
    "    # 1. 趋势判断 (宽松化：允许部分零值)\n",
    "    is_mostly_increasing = all(d >= 0 for d in diff_list)\n",
    "    is_mostly_decreasing = all(d <= 0 for d in diff_list)\n",
    "\n",
    "    if is_mostly_increasing:\n",
    "        semantics.append(\"increase\")\n",
    "    elif is_mostly_decreasing:\n",
    "        semantics.append(\"decrease\")\n",
    "        \n",
    "    if is_time_or_counter and is_mostly_increasing:\n",
    "        # 针对时间/计数器，只要大部分时间在增加，就认为是正常自增\n",
    "        return \"incrementing\" \n",
    "    \n",
    "    # 2. 异常判断 (仅对非时间/计数器的物理量才判断大幅突变)\n",
    "    # 如果是时间/计数器，跳过 JUMP_THRESHOLD 判断，除非阈值专门针对时间设计\n",
    "    if not is_time_or_counter and any(abs(d) > JUMP_THRESHOLD for d in diff_list):\n",
    "        semantics.append(\"abnormal_jump\")\n",
    "        \n",
    "    # 3. 震荡判断 (符号翻转)\n",
    "    if len(diff_list) > 1:\n",
    "        # 忽略极小的浮点数变化\n",
    "        sign_changes = sum(1 for i in range(1, len(diff_list)) \n",
    "                           if diff_list[i] * diff_list[i-1] < 0 and \n",
    "                           abs(diff_list[i]) > 1e-6 and abs(diff_list[i-1]) > 1e-6)\n",
    "        \n",
    "        if sign_changes > 0:\n",
    "            semantics.append(\"fluctuation\")\n",
    "\n",
    "    semantics = list(set(semantics))\n",
    "    if semantics:\n",
    "        return semantics if len(semantics) > 1 else semantics[0]\n",
    "\n",
    "    # 无法被定义为上述任何语义，则标记为复杂变化\n",
    "    return \"complex_change\"\n",
    "\n",
    "def generate_optimized(df, diff_window=3):\n",
    "    labels = df[\"Label\"] if \"Label\" in df.columns else [None]*len(df)\n",
    "    df_no_label = df.drop(columns=[\"Label\"], errors='ignore')\n",
    "    columns = df_no_label.columns.tolist()\n",
    "    numeric_cols = df_no_label.select_dtypes(include=[np.number]).columns\n",
    "    TIME_COUNTER_COLS = [\n",
    "        col for col in numeric_cols \n",
    "        if \"time\" in col.lower() or \"ts\" in col.lower() or \"smpcnt\" in col.lower() or \"sqnum\" in col.lower()\n",
    "    ]\n",
    "    groups = extract_groups(columns)\n",
    "\n",
    "    df_diff = df_no_label[numeric_cols].diff().fillna(0)\n",
    "\n",
    "    event_sequences = []\n",
    "    diff_vectors = []\n",
    "\n",
    "    # 转换为 dict 列表以便快速迭代\n",
    "    records = df_no_label.to_dict('records')\n",
    "    diff_records = df_diff.to_dict('records')\n",
    "    \n",
    "    # 用于存储最近 N 个 diff 值的 rolling buffer\n",
    "    # 结构: {col_name: [diff_t-2, diff_t-1, diff_t]}\n",
    "    rolling_diffs = {col: [] for col in columns}\n",
    "\n",
    "    print(f\"Processing {len(records)} rows...\")\n",
    "\n",
    "    for i, row in enumerate(records):\n",
    "        # A. 生成文本 Log\n",
    "        seq = row_to_single_log(row, columns, groups)\n",
    "        event_sequences.append(seq)\n",
    "\n",
    "        # B. 生成 Diff Vector\n",
    "        row_diff_vec = {}\n",
    "        current_diff_row = diff_records[i] if i < len(diff_records) else {}\n",
    "\n",
    "        for col, val in row.items():\n",
    "            # 跳过非关键列（如单纯的时间戳列，视情况而定）\n",
    "            \n",
    "            # Case 1: Boolean / String (状态量)\n",
    "            # 使用原始值比较 (Current vs Previous)\n",
    "            prev_val = records[i-1][col] if i > 0 else val\n",
    "            \n",
    "            if isinstance(val, (bool, str)) or (isinstance(val, (int, float)) and col not in numeric_cols):\n",
    "                if val == prev_val:\n",
    "                    sem = \"state_hold\"\n",
    "                else:\n",
    "                    if isinstance(val, bool) and isinstance(prev_val, bool):\n",
    "                        sem = \"trip_activation\" if (not prev_val and val) else \"state_drop\"\n",
    "                    else:\n",
    "                        sem = \"state_change\"\n",
    "                \n",
    "                # 对于状态量，只记录语义\n",
    "                if sem != \"state_hold\": \n",
    "                     row_diff_vec[col] = sem\n",
    "\n",
    "            # Case 2: Numeric (模拟量/时间/计数器)\n",
    "            elif col in numeric_cols:\n",
    "                d_val = current_diff_row.get(col, 0.0)\n",
    "                rolling_diffs[col].append(d_val)\n",
    "                if len(rolling_diffs[col]) > diff_window:\n",
    "                    rolling_diffs[col].pop(0)\n",
    "                \n",
    "                current_window_diffs = rolling_diffs[col]\n",
    "                \n",
    "                is_tc = col in TIME_COUNTER_COLS \n",
    "                sem = analyze_numeric_diffs(current_window_diffs, is_time_or_counter=is_tc)\n",
    "                \n",
    "                # 如果是时间/计数器，并且是 incrementing，只保留 sem\n",
    "                if is_tc and sem == \"incrementing\":\n",
    "                    row_diff_vec[col] = \"incrementing\" # 进一步压缩\n",
    "                else:\n",
    "                    # 对于物理量或非正常的时间/计数器变化，保留 delta 列表\n",
    "                    formatted_diffs = [round(x, 3) for x in current_window_diffs]\n",
    "                    row_diff_vec[col] = {\n",
    "                        \"delta\": formatted_diffs, \n",
    "                        \"sem\": sem \n",
    "                    }\n",
    "            \n",
    "        diff_vectors.append(row_diff_vec)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Label\": labels,\n",
    "        \"Event_sequence\": event_sequences,\n",
    "        \"Diff_vector\": diff_vectors\n",
    "    })\n",
    "\n",
    "def _json_safe(obj):\n",
    "    if isinstance(obj, (np.integer, int)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, (np.floating, float)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, (np.bool_, bool)):\n",
    "        return bool(obj)\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return str(obj)\n",
    "\n",
    "def main(input_path: str):\n",
    "    try:\n",
    "        if input_path.endswith('.csv'):\n",
    "            df = pd.read_csv(input_path)\n",
    "        else:\n",
    "            df = pd.read_excel(input_path)\n",
    "        print(f\"Loaded data: {len(df)} rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return\n",
    "\n",
    "    out_df = generate_optimized(df, diff_window=3)\n",
    "\n",
    "    # 序列化\n",
    "    p = Path(input_path)\n",
    "    parent_name = p.parent.name or p.stem\n",
    "    out_csv = f\"{parent_name}.csv\"\n",
    "    print(f\"Output file will be: {out_csv}\")\n",
    "    out_df[\"Diff_vector\"] = out_df[\"Diff_vector\"].apply(\n",
    "        lambda d: json.dumps(d, ensure_ascii=False, default=_json_safe)\n",
    "    )\n",
    "    \n",
    "    out_df.to_csv(out_csv, index=False)\n",
    "    print(f\"Success! Wrote to {out_csv}\")\n",
    "    \n",
    "import os\n",
    "from pathlib import Path\n",
    "if __name__ == \"__main__\":   \n",
    "    #main('./974/974d/QUTZS_final.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    root_dir = Path(\"./Benign-behaviour-only\")\n",
    "\n",
    "    print(\"Searching in:\", root_dir)\n",
    "\n",
    "    # 忽略大小写搜索 xlsx\n",
    "    xlsx_files = list(root_dir.rglob(\"*QUTZS_final.xlsx\"))\n",
    "\n",
    "    print(f\"Found {len(xlsx_files)} files.\")\n",
    "\n",
    "    for xlsx_path in xlsx_files:\n",
    "        print(\"\\nProcessing:\", xlsx_path)\n",
    "        #df = pd.read_excel(xlsx_path)\n",
    "        main(xlsx_path)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78becb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goose_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
